{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6621e68a-70ec-4109-bb59-3384676a1d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pdb import run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1326b09a-4f0e-4c20-a436-feb05f152325",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the TSV file, using header=None since there is no header row\n",
    "df_train = pd.read_csv('ACSF1_TRAIN.tsv', sep='\\t', header=None)\n",
    "df_test = pd.read_csv('ACSF1_TEST.tsv', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "779d2dd0-921d-4956-9226-26fc39378685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Labels shape: (100,)\n",
      "train Data shape:  (100, 1460)\n"
     ]
    }
   ],
   "source": [
    "#  Separate labels and data of train \n",
    "labels_train = df_train.iloc[:, 0].values        \n",
    "data_train = df_train.iloc[:, 1:]     \n",
    "print(\"train Labels shape:\", labels_train.shape)\n",
    "print(\"train Data shape: \", data_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d1d6471-f69f-4bf8-974b-cc0ca3d6804e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Labels shape: (100,)\n",
      "test Data shape:  (100, 1460)\n"
     ]
    }
   ],
   "source": [
    "#  Separate labels and data of test \n",
    "labels_test = df_test.iloc[:, 0].values        \n",
    "data_test = df_test.iloc[:, 1:]     \n",
    "print(\"test Labels shape:\", labels_test.shape)\n",
    "print(\"test Data shape: \", data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbe65060-48fe-4ae5-b2ff-2003e311da84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Any missing values in the train dataset? False\n",
      "\n",
      "Any missing values in the test dataset? False\n"
     ]
    }
   ],
   "source": [
    "#  Verify there are no missing values\n",
    "print(\"\\nAny missing values in the train dataset?\", data_train.isnull().any().any())\n",
    "print(\"\\nAny missing values in the test dataset?\", data_test.isnull().any().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3df96a48-da3b-471b-89a5-f117cbc76def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       1         2         3         4         5         6         7     \\\n",
      "0 -0.584754 -0.584754  1.730991 -0.584754 -0.584754 -0.584754  1.729917   \n",
      "1 -0.591434 -0.511104  1.726820 -0.580422 -0.591434 -0.511104  1.727921   \n",
      "2 -0.577945 -0.577945  1.730793 -0.577945 -0.578946 -0.564882  1.731094   \n",
      "3 -0.588925 -0.538088  1.735718 -0.588716 -0.589962 -0.523551  1.735619   \n",
      "4 -0.596633 -0.532188  1.718067 -0.592117 -0.596633 -0.532188  1.715241   \n",
      "\n",
      "       8         9         10    ...      1451      1452      1453      1454  \\\n",
      "0 -0.584754 -0.584754 -0.584754  ...  1.732726 -0.584734 -0.583729 -0.578603   \n",
      "1 -0.580422 -0.591434 -0.511104  ...  1.727396 -0.580731 -0.580731 -0.580731   \n",
      "2 -0.577829 -0.580956 -0.548788  ...  1.734727 -0.577751 -0.580956 -0.549798   \n",
      "3 -0.588646 -0.588925 -0.524598  ...  1.743664 -0.588876 -0.586852 -0.576483   \n",
      "4 -0.592117 -0.595605 -0.532188  ...  1.743258 -0.592403 -0.591524 -0.575158   \n",
      "\n",
      "       1455      1456      1457      1458      1459      1460  \n",
      "0  1.732726 -0.584734 -0.583729 -0.578603  1.732726 -0.584734  \n",
      "1  1.727396 -0.580731 -0.580731 -0.580731  1.727396 -0.580731  \n",
      "2  1.734727 -0.577751 -0.580956 -0.549798  1.734727 -0.577751  \n",
      "3  1.743664 -0.588876 -0.586852 -0.576483  1.743664 -0.588876  \n",
      "4  1.743258 -0.592403 -0.591524 -0.575158  1.743258 -0.592403  \n",
      "\n",
      "[5 rows x 1460 columns]\n",
      "       1         2         3         4         5         6         7     \\\n",
      "0 -0.577967 -0.577967  1.738162 -0.577967 -0.577967 -0.577967  1.736333   \n",
      "1 -0.588575 -0.588575  1.723134 -0.588575 -0.588575 -0.588575  1.724207   \n",
      "2 -0.582897 -0.573761  1.753402 -0.582838 -0.582897 -0.582897  1.754501   \n",
      "3 -0.590951 -0.537474  1.743933 -0.590733 -0.591978 -0.527198  1.715386   \n",
      "4 -0.576821 -0.563665  1.730566 -0.577710 -0.576821 -0.563665  1.729412   \n",
      "\n",
      "       8         9         10    ...      1451      1452      1453      1454  \\\n",
      "0 -0.577967 -0.577967 -0.577967  ...  1.716743 -0.577967 -0.577967 -0.577967   \n",
      "1 -0.588575 -0.588575 -0.588575  ...  1.742432 -0.588430 -0.591796 -0.554190   \n",
      "2 -0.582897 -0.585939 -0.555469  ...  1.724040 -0.582681 -0.585939 -0.553437   \n",
      "3 -0.590684 -0.591978 -0.527198  ...  1.728123 -0.590891 -0.588895 -0.575526   \n",
      "4 -0.577710 -0.576821 -0.563665  ...  1.739030 -0.577828 -0.577828 -0.577828   \n",
      "\n",
      "       1455      1456      1457      1458      1459      1460  \n",
      "0  1.716743 -0.577967 -0.577967 -0.577967  1.716743 -0.577967  \n",
      "1  1.742432 -0.588430 -0.591796 -0.554190  1.742432 -0.588430  \n",
      "2  1.724040 -0.582681 -0.585939 -0.553437  1.724040 -0.582681  \n",
      "3  1.728123 -0.590891 -0.588895 -0.575526  1.728123 -0.590891  \n",
      "4  1.739030 -0.577828 -0.577828 -0.577828  1.739030 -0.577828  \n",
      "\n",
      "[5 rows x 1460 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data_train.head())     # First 5 rows of train data\n",
    "print(data_test.head())      # First 5 rows of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9e66fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deterministic_train_test_split(data, labels, step=10, run=0, val_ratio=0.2):\n",
    "    \"\"\"\n",
    "    Deterministic split: select validation indices spaced by 'step' to achieve 'val_ratio' split.\n",
    "    \"\"\"\n",
    "    n = len(data)\n",
    "    block_size = int(np.ceil(n * val_ratio))\n",
    "    start = run * block_size * step\n",
    "    val_idx = [(start + i * step) % n for i in range(block_size)]\n",
    "    train_idx = np.setdiff1d(np.arange(n), val_idx)\n",
    "    data_training = data.iloc[train_idx].reset_index(drop=True)\n",
    "    data_validation = data.iloc[val_idx].reset_index(drop=True)\n",
    "    labels_training = labels[train_idx]\n",
    "    labels_validation = labels[val_idx]\n",
    "    return data_training, data_validation, labels_training, labels_validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0082157c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_otw_smooth_signed(X1, X2, m, s, beta):\n",
    "    \"\"\"\n",
    "    Compute pairwise OTW distances between all rows of X1 and X2.\n",
    "    Returns: (N1, N2) distance matrix.\n",
    "    \"\"\"\n",
    "\n",
    "    # Smooth absolute value function\n",
    "    def smooth_abs(x, beta):\n",
    "        if abs(x) < beta:\n",
    "            return x**2 / (2 * beta)\n",
    "        else:\n",
    "            return abs(x) - beta/2\n",
    "\n",
    "    # Split positive/negative parts\n",
    "    def split_pos_neg(x):\n",
    "        x_pos = np.maximum(x, 0)\n",
    "        x_neg = np.maximum(-x, 0)\n",
    "        return x_pos, x_neg\n",
    "\n",
    "    # OTW computation for positive or negative parts\n",
    "    def otw_smooth(a, b, m, s, beta):\n",
    "        # Cumulative sums\n",
    "        A = np.cumsum(a)\n",
    "        B = np.cumsum(b)\n",
    "        n = len(a)\n",
    "        diffs = 0.0\n",
    "        for i in range(1, n):\n",
    "            As = A[i] - (A[i-s] if i >= s else 0.0)\n",
    "            Bs = B[i] - (B[i-s] if i >= s else 0.0)\n",
    "            diffs += smooth_abs(As - Bs, beta)\n",
    "        An = A[-1] - (A[-1-s] if n-1 >= s else 0.0)\n",
    "        Bn = B[-1] - (B[-1-s] if n-1 >= s else 0.0)\n",
    "        return m * smooth_abs(An - Bn, beta) + diffs\n",
    "\n",
    "    # Split into positive and negative parts\n",
    "    a_pos, a_neg = split_pos_neg(X1)\n",
    "    b_pos, b_neg = split_pos_neg(X2)\n",
    "    \n",
    "    # Compute OTW for positive and negative parts\n",
    "    otw_pos = otw_smooth(a_pos, b_pos, m, s, beta)\n",
    "    otw_neg = otw_smooth(a_neg, b_neg, m, s, beta)\n",
    "\n",
    "    return otw_pos + otw_neg \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f378279d-24df-4a06-99f1-c10a83cf98bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 1\n",
    "s = 5\n",
    "beta = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8125c716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# 10 time training and validation split and average the error\n",
    "error_list = []\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    data_training, data_validation, labels_training, labels_validation = deterministic_train_test_split(\n",
    "        data_train, labels_train, step=8, run=i, val_ratio=0.2\n",
    "    )\n",
    "    \n",
    "    results = []\n",
    "    for k in range(data_validation.shape[0]):\n",
    "        x = data_validation.iloc[k].values\n",
    "        dists = []\n",
    "        for j in range(data_training.shape[0]):\n",
    "            y = data_training.iloc[j].values\n",
    "            d = pairwise_otw_smooth_signed(x, y, m, s, beta)\n",
    "            dists.append(d)\n",
    "        nn_idx = np.argmin(dists)\n",
    "        pred = labels_training[nn_idx]\n",
    "        results.append(int(pred))\n",
    "    error_list.append(np.mean(np.array(results) != np.array(labels_validation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fef8d129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OTW classification validation error rates over 10 runs: [0.35 0.35 0.25 0.35 0.45 0.35 0.35 0.25 0.35 0.45]\n",
      "OTW classification validation error rate: 0.35 ± 0.04\n"
     ]
    }
   ],
   "source": [
    "error_list = np.array(error_list, dtype=np.float64)\n",
    "print (\"OTW classification validation error rates over 10 runs:\", error_list)\n",
    "n = len(error_list)\t\n",
    "mean_error = np.mean(error_list)\n",
    "std_error = np.std(error_list)\n",
    "margin_error = 1.96 * std_error / np.sqrt(n) # 95% confidence interval\n",
    "print(f\"OTW classification validation error rate: {mean_error:.2f} ± {margin_error:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "647b1dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test sample 0/100\n",
      "Processing test sample 10/100\n",
      "Processing test sample 20/100\n",
      "Processing test sample 30/100\n",
      "Processing test sample 40/100\n",
      "Processing test sample 50/100\n",
      "Processing test sample 60/100\n",
      "Processing test sample 70/100\n",
      "Processing test sample 80/100\n",
      "Processing test sample 90/100\n",
      "OTW classification test error rate on the test set: 0.35\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation on the test set\n",
    "results = []\n",
    "for i in range(len(data_test)):\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Processing test sample {i}/{len(data_test)}\")\n",
    "    x = data_test.iloc[i].to_numpy() \n",
    "    dists = []\n",
    "    for j in range(len(data_train)):\n",
    "        y = data_train.iloc[j].to_numpy()\n",
    "        d = pairwise_otw_smooth_signed(x, y, m, s, beta)\n",
    "        dists.append(d)\n",
    "    nn_idx = np.argmin(dists)\n",
    "    pred = labels_train[nn_idx] \n",
    "    results.append(pred)\n",
    "results = np.array(results)\n",
    "# Compute error\n",
    "error = np.mean(results != labels_test)\n",
    "print(\"OTW classification test error rate on the test set: {:.2f}\".format(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a625dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d9452e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
